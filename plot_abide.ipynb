{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as op\n",
    "\n",
    "# Remove any preset backend\n",
    "os.environ.pop(\"MPLBACKEND\", None)\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "# Choose a non‑interactive file backend (you can switch to \"TkAgg\" if you want pop‑up windows)\n",
    "matplotlib.use(\"agg\")\n",
    "\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "from neuromaps import transforms\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import pandas as pd\n",
    "from gradec.utils import _zero_medial_wall\n",
    "import nibabel as nib\n",
    "from nilearn import datasets\n",
    "from nilearn.plotting.cm import _cmap_d as nilearn_cmaps\n",
    "from surfplot import Plot\n",
    "from nilearn import datasets\n",
    "from gradec.plot import plot_radar, plot_cloud\n",
    "from gradec.fetcher import _fetch_features, _fetch_frequencies, _fetch_classification\n",
    "from gradec.utils import _decoding_filter\n",
    "from nimare.decode.continuous import CorrelationDecoder\n",
    "import numpy as np\n",
    "from nilearn.maskers import NiftiMasker\n",
    "from nilearn.image import threshold_img, index_img\n",
    "from neuromaps.datasets import fetch_fslr\n",
    "from nimare.transforms import p_to_z\n",
    "from nilearn.plotting import plot_stat_map\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import nilearn.reporting\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from nilearn import datasets, plotting, image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "CMAP = nilearn_cmaps[\"cold_hot\"]\n",
    "CMAP = \"Spectral_r\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_image(img=None, tol=1, fix=True):\n",
    "    if fix:\n",
    "        mask = img != tol\n",
    "    else:\n",
    "        mask = img <= tol\n",
    "    if img.ndim == 3:\n",
    "        mask = mask.any(2)\n",
    "    mask0, mask1 = mask.any(0), mask.any(1)\n",
    "    return img[np.ix_(mask1, mask0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_vol(\n",
    "    nii_img_thr, threshold, mask_contours=None, vmax=6, alpha=1, cmap=CMAP, dim=-0.45, cut_coords=1\n",
    "):\n",
    "    template = datasets.load_mni152_template(resolution=1)\n",
    "\n",
    "    display_modes = [\"x\", \"y\", \"z\"]\n",
    "    fig = plt.figure(figsize=(5, 5))\n",
    "    fig.subplots_adjust(\n",
    "        left=None, bottom=None, right=None, top=None, wspace=None, hspace=None\n",
    "    )\n",
    "    gs = GridSpec(2, 2, figure=fig)\n",
    "\n",
    "    for dsp_i, display_mode in enumerate(display_modes):\n",
    "        if display_mode == \"z\":\n",
    "            ax = fig.add_subplot(gs[:, 1], aspect=\"equal\")\n",
    "            colorbar = True\n",
    "        else:\n",
    "            ax = fig.add_subplot(gs[dsp_i, 0], aspect=\"equal\")\n",
    "            colorbar = False\n",
    "\n",
    "        display = plot_stat_map(\n",
    "            nii_img_thr,\n",
    "            bg_img=template,\n",
    "            black_bg=False,\n",
    "            draw_cross=False,\n",
    "            annotate=True,\n",
    "            alpha=alpha,\n",
    "            cmap=cmap,\n",
    "            threshold=threshold,\n",
    "            colorbar=colorbar,\n",
    "            display_mode=display_mode,\n",
    "            cut_coords=cut_coords,\n",
    "            vmax=vmax,\n",
    "            axes=ax,\n",
    "            dim=dim,  # Adjusted dimming factor\n",
    "        )\n",
    "        if mask_contours:\n",
    "            display.add_contours(mask_contours, levels=[0.5], colors=\"black\")\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_vol2(\n",
    "    nii_img_thr, threshold, mask_contours=None, vmax=6, alpha=1, cmap=CMAP, dim=-0.45\n",
    "):\n",
    "    template = datasets.load_mni152_template(resolution=1)\n",
    "\n",
    "    # Create a figure with 9 subplots in a single row\n",
    "    fig, axes = plt.subplots(1, 9, figsize=(27, 3))\n",
    "\n",
    "    # Define slices for x, y, z directions\n",
    "    '''slices_x = [2, 15, -4]\n",
    "    slices_y = [-18, -33, -41]\n",
    "    slices_z = [18, -1, 2]'''\n",
    "\n",
    "    slices_x = [45, -54, -4]\n",
    "    slices_y = [-18, -41, -41]\n",
    "    slices_z = [2, -9, 2]\n",
    "\n",
    "    # Combine all slices into a single list for easy iteration\n",
    "    slices = slices_x + slices_y + slices_z\n",
    "    display_modes = [\"x\"] * 3 + [\"y\"] * 3 + [\"z\"] * 3\n",
    "\n",
    "    # Iterate over the slices and axes\n",
    "    for i, (slice, display_mode, ax) in enumerate(zip(slices, display_modes, axes)):\n",
    "        display = plot_stat_map(\n",
    "            nii_img_thr,\n",
    "            bg_img=template,\n",
    "            display_mode=display_mode,\n",
    "            cut_coords=[slice],\n",
    "            black_bg=False,\n",
    "            draw_cross=False,\n",
    "            annotate=True,\n",
    "            alpha=alpha,\n",
    "            cmap=cmap,\n",
    "            threshold=threshold,\n",
    "            colorbar=False,  # Disable individual colorbars\n",
    "            vmax=vmax,\n",
    "            dim=dim,  # Adjusted dimming factor\n",
    "            axes=ax,\n",
    "        )\n",
    "\n",
    "        if mask_contours:\n",
    "            display.add_contours(mask_contours, levels=[0.5], colors=\"black\")\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 0.9, 1])  # Adjust the layout to fit the colorbar\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_surf(nii_img_thr, mask_contours=None, vmax=8, cmap=CMAP):\n",
    "    map_lh, map_rh = transforms.mni152_to_fslr(nii_img_thr, fslr_density=\"32k\")\n",
    "    map_lh, map_rh = _zero_medial_wall(\n",
    "        map_lh,\n",
    "        map_rh,\n",
    "        space=\"fsLR\",\n",
    "        density=\"32k\",\n",
    "    )\n",
    "    # midthickness\n",
    "\n",
    "    surfaces = fetch_fslr(density=\"32k\")\n",
    "    lh, rh = surfaces[\"inflated\"]\n",
    "    sulc_lh, sulc_rh = surfaces[\"sulc\"]\n",
    "\n",
    "    p = Plot(surf_lh=lh, surf_rh=rh, layout=\"grid\")\n",
    "    p.add_layer({\"left\": sulc_lh, \"right\": sulc_rh}, cmap=\"binary_r\", cbar=False)\n",
    "    p.add_layer(\n",
    "        {\"left\": map_lh, \"right\": map_rh},\n",
    "        cmap=cmap,\n",
    "        cbar=False,\n",
    "        color_range=(-vmax, vmax)\n",
    "    )\n",
    "    if mask_contours:\n",
    "        mask_lh, mask_rh = transforms.mni152_to_fslr(mask_contours, fslr_density=\"32k\")\n",
    "        mask_lh, mask_rh = _zero_medial_wall(\n",
    "            mask_lh,\n",
    "            mask_rh,\n",
    "            space=\"fsLR\",\n",
    "            density=\"32k\",\n",
    "        )\n",
    "        mask_arr_lh = mask_lh.agg_data()\n",
    "        mask_arr_rh = mask_rh.agg_data()\n",
    "        countours_lh = np.zeros_like(mask_arr_lh)\n",
    "        countours_lh[mask_arr_lh != 0] = 1\n",
    "        countours_rh = np.zeros_like(mask_arr_rh)\n",
    "        countours_rh[mask_arr_rh != 0] = 1\n",
    "\n",
    "        colors = [(0, 0, 0, 0)]\n",
    "        contour_cmap = ListedColormap(colors, 'regions', N=1)\n",
    "        line_cmap = ListedColormap([\"black\"], 'regions', N=1)\n",
    "        p.add_layer(\n",
    "            {\"left\": countours_lh, \"right\": countours_rh}, \n",
    "            cmap=line_cmap, \n",
    "            as_outline=True, \n",
    "            cbar=False\n",
    "        )\n",
    "        p.add_layer(\n",
    "            {\"left\": countours_lh, \"right\": countours_rh},\n",
    "            cmap=contour_cmap,\n",
    "            cbar=False,\n",
    "        )\n",
    "    \n",
    "    return p.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./dset\"\n",
    "out_dir = \"./derivatives\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "DSET, MODEL = \"neuroquery\", \"lda\"\n",
    "decoding_dir = \"./decoding\"\n",
    "decoder_fn = op.join(data_dir, f\"{MODEL}_{DSET}_decoder.pkl.gz\")\n",
    "\n",
    "decoder = CorrelationDecoder.load(decoder_fn)\n",
    "\n",
    "features = _fetch_features(DSET, MODEL, data_dir=decoding_dir)\n",
    "frequencies = _fetch_frequencies(DSET, MODEL, data_dir=decoding_dir)\n",
    "classification, class_lst = _fetch_classification(DSET, MODEL, data_dir=decoding_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_img = datasets.load_mni152_brain_mask(resolution=1)\n",
    "masker = NiftiMasker(mask_img=mask_img)\n",
    "masker = masker.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = {\n",
    "    \"1s\": \"Group Average (One-Sample T-Test)\",\n",
    "    \"2s\": \"Group Comparison (Two-Sample Unpaired T-Test: ASD-TD)\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster correction table:\n",
      "     pthr  .10000  .05000  .02000  .01000\n",
      "0  0.0500  1482.6  1773.0  2163.0  2497.0\n",
      "1  0.0200   518.3   623.0   768.0   880.0\n",
      "2  0.0100   283.8   343.1   423.0   489.5\n",
      "3  0.0050   168.3   205.7   254.7   298.3\n",
      "4  0.0020    93.8   113.8   141.8   168.5\n",
      "5  0.0010    62.3    76.7    97.0   116.7\n",
      "6  0.0005    43.1    53.9    67.7    79.7\n",
      "7  0.0002    27.0    33.7    44.0    53.0\n",
      "8  0.0001    18.9    24.4    31.8    38.8\n",
      "Total subjects: 1584, Group sizes: 705, 879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b0/6xxmhnys7hj9g_47_dsjm7c00000gn/T/ipykernel_80491/1091506867.py:23: FutureWarning: The 'delim_whitespace' keyword in pd.read_table is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  cluster_df = pd.read_table(cluster_fn, skiprows=8, delim_whitespace=True, names=column_names)\n"
     ]
    }
   ],
   "source": [
    "# Setup directories and file paths\n",
    "group_dir = op.join(data_dir, \"group/habenula_mni_dilated\")\n",
    "group_avg_dir = op.join(out_dir, \"group-averaged\")\n",
    "group_diff_dir = op.join(out_dir, \"group-difference\")\n",
    "\n",
    "# File paths\n",
    "brik_fn = op.join(\n",
    "    group_dir, \"sub-group_task-rest_desc-1S2StTesthabenula_briks+tlrc.BRIK\"\n",
    ")\n",
    "table_fn = op.join(group_dir, \"sub-group_task-rest_desc-1S2StTesthabenula_table.txt\")\n",
    "nii_1s_fn = op.join(\n",
    "    group_avg_dir, \"sub-group_task-rest_desc-1SampletTest.nii.gz\"\n",
    ")\n",
    "nii_2s_fn = op.join(\n",
    "    group_diff_dir, \"sub-group_task-rest_desc-2SampletTest.nii.gz\"\n",
    ")\n",
    "cluster_fn = op.join(\n",
    "    data_dir, \"clustsim\", \"clustsim_out.NN2_2sided.1D\"\n",
    ")\n",
    "\n",
    "# Load cluster correction table\n",
    "column_names = [\".10000\", \".05000\", \".02000\", \".01000\"]\n",
    "cluster_df = pd.read_table(cluster_fn, skiprows=8, delim_whitespace=True, names=column_names)\n",
    "cluster_df = cluster_df.reset_index()\n",
    "cluster_df.rename(columns={'index': 'pthr'}, inplace=True)\n",
    "print(\"Cluster correction table:\")\n",
    "print(cluster_df)\n",
    "\n",
    "# Analysis parameters\n",
    "brik_idx = [8, 10]\n",
    "nii_fns = [nii_1s_fn, nii_2s_fn]\n",
    "tests = [\"1s\", \"2s\"]\n",
    "alpha = \".01000\"\n",
    "pthrs = [0.0001, 0.0001]\n",
    "cohen_thresh = 0\n",
    "\n",
    "# Load participant data for effect size calculations\n",
    "data_df = pd.read_csv(table_fn, sep=\"\\t\")\n",
    "n_sub = data_df.groupby(\"group\").size().sum()\n",
    "n_sub_1, n_sub_2 = data_df.groupby(\"group\").size().values\n",
    "print(f\"Total subjects: {n_sub}, Group sizes: {n_sub_1}, {n_sub_2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing Group Average (One-Sample T-Test) ===\n",
      "File ./derivatives/group-averaged/sub-group_task-rest_desc-1SampletTest.nii.gz already exists, skipping conversion.\n",
      "Cluster extent: 38.8, p-threshold: 0.0001, z-threshold: 3.890591886413094\n",
      "Cluster extent: 38.8, p-threshold: 0.0001, z-threshold: 3.890591886413094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chloehampson/Desktop/habenula-abide-rsfc/.venv/lib/python3.9/site-packages/nilearn/maskers/nifti_masker.py:108: UserWarning: imgs are being resampled to the mask_img resolution. This process is memory intensive. You might want to provide a target_affine that is equal to the affine of the imgs or resample the mask beforehand to save memory and computation time.\n",
      "  warnings.warn(\n",
      "/Users/chloehampson/Desktop/habenula-abide-rsfc/.venv/lib/python3.9/site-packages/nilearn/maskers/nifti_masker.py:108: UserWarning: imgs are being resampled to the mask_img resolution. This process is memory intensive. You might want to provide a target_affine that is equal to the affine of the imgs or resample the mask beforehand to save memory and computation time.\n",
      "  warnings.warn(\n",
      "/Users/chloehampson/Desktop/habenula-abide-rsfc/.venv/lib/python3.9/site-packages/nilearn/maskers/nifti_masker.py:108: UserWarning: imgs are being resampled to the mask_img resolution. This process is memory intensive. You might want to provide a target_affine that is equal to the affine of the imgs or resample the mask beforehand to save memory and computation time.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Significant clusters:\n",
      "   Cluster ID     X     Y     Z  Peak Stat Cluster Size (mm3)\n",
      "0           1  -0.5 -28.5   1.5  38.277458             645336\n",
      "1          1a   5.5  -2.5   1.5  17.070114                   \n",
      "2          1b  13.5 -30.5  -4.5  15.703444                   \n",
      "3          1c  -0.5 -22.5 -18.5  14.814359                   \n",
      "4           2 -28.5  33.5  25.5   6.612488               3728\n",
      "5          2a -24.5  23.5  41.5   5.389577                   \n",
      "6          2b -32.5  39.5  33.5   5.230610                   \n",
      "7          2c -28.5  35.5  39.5   5.091123                   \n",
      "8           3  25.5  31.5  39.5   6.094035               3536\n",
      "9          3a  31.5  37.5  25.5   5.589732                   \n",
      "10         3b  21.5  31.5  45.5   5.528059                   \n",
      "11         3c  37.5  31.5  31.5   5.076546                   \n",
      "12          4 -32.5 -56.5  43.5   6.044006                936\n",
      "13          5 -20.5 -44.5  71.5   5.870116                488\n",
      "14         5a -26.5 -42.5  65.5   4.163960                   \n",
      "15          6 -22.5 -30.5  69.5   4.973697                904\n",
      "16         6a -20.5 -30.5  59.5   4.787635                   \n",
      "17          7  27.5  53.5   5.5   4.841272                480\n",
      "18         7a  25.5  57.5  -2.5   4.363590                   \n",
      "19          1 -18.5  -6.5  31.5  -9.124745              16136\n",
      "20         1a  19.5  35.5   3.5  -8.704480                   \n",
      "21         1b  17.5  -6.5  31.5  -8.468498                   \n",
      "22         1c  21.5   3.5  29.5  -7.290205                   \n",
      "23          2 -30.5 -42.5   9.5  -6.965358                528\n",
      "24          3  29.5 -40.5  21.5  -6.234859               2792\n",
      "25         3a  17.5 -40.5  17.5  -5.880063                   \n",
      "26         3b  31.5 -38.5  15.5  -5.686663                   \n",
      "27         3c  29.5 -48.5  19.5  -5.415320                   \n",
      "Saved thresholded nifti: ./derivatives/group-averaged/sub-group_task-rest_desc-1SampletTest_thresh.nii.gz\n",
      "Generating visualizations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b0/6xxmhnys7hj9g_47_dsjm7c00000gn/T/ipykernel_80491/3772498051.py:7: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  fig = plt.figure(figsize=(5, 5))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved figures to ./derivatives/group-averaged\n",
      "==================================================\n",
      "\n",
      "=== Processing Group Comparison (Two-Sample Unpaired T-Test: ASD-TD) ===\n",
      "File ./derivatives/group-difference/sub-group_task-rest_desc-2SampletTest.nii.gz already exists, skipping conversion.\n",
      "Cluster extent: 38.8, p-threshold: 0.0001, z-threshold: 3.890591886413094\n",
      "Cluster extent: 38.8, p-threshold: 0.0001, z-threshold: 3.890591886413094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chloehampson/Desktop/habenula-abide-rsfc/.venv/lib/python3.9/site-packages/nilearn/maskers/nifti_masker.py:108: UserWarning: imgs are being resampled to the mask_img resolution. This process is memory intensive. You might want to provide a target_affine that is equal to the affine of the imgs or resample the mask beforehand to save memory and computation time.\n",
      "  warnings.warn(\n",
      "/Users/chloehampson/Desktop/habenula-abide-rsfc/.venv/lib/python3.9/site-packages/nilearn/maskers/nifti_masker.py:108: UserWarning: imgs are being resampled to the mask_img resolution. This process is memory intensive. You might want to provide a target_affine that is equal to the affine of the imgs or resample the mask beforehand to save memory and computation time.\n",
      "  warnings.warn(\n",
      "/Users/chloehampson/Desktop/habenula-abide-rsfc/.venv/lib/python3.9/site-packages/nilearn/maskers/nifti_masker.py:108: UserWarning: imgs are being resampled to the mask_img resolution. This process is memory intensive. You might want to provide a target_affine that is equal to the affine of the imgs or resample the mask beforehand to save memory and computation time.\n",
      "  warnings.warn(\n",
      "/Users/chloehampson/Desktop/habenula-abide-rsfc/.venv/lib/python3.9/site-packages/nilearn/reporting/_get_clusters_table.py:339: UserWarning: Attention: No clusters with stat lower than -3.890591886413094\n",
      "  warnings.warn(\n",
      "/Users/chloehampson/Desktop/habenula-abide-rsfc/.venv/lib/python3.9/site-packages/nilearn/reporting/_get_clusters_table.py:339: UserWarning: Attention: No clusters with stat lower than -3.890591886413094\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Significant clusters:\n",
      "  Cluster ID     X     Y     Z  Peak Stat Cluster Size (mm3)\n",
      "0          1  59.5 -38.5  -0.5   5.402785               1256\n",
      "1         1a  47.5 -40.5   3.5   4.879167                   \n",
      "2         1b  69.5 -38.5  -0.5   4.619359                   \n",
      "3          2 -52.5 -24.5  -2.5   4.930276               1160\n",
      "4         2a -60.5 -28.5   3.5   4.642123                   \n",
      "5         2b -60.5 -30.5  -4.5   4.306325                   \n",
      "6          3 -60.5 -12.5  35.5   4.861617                480\n",
      "Saved thresholded nifti: ./derivatives/group-difference/sub-group_task-rest_desc-2SampletTest_thresh.nii.gz\n",
      "Generating visualizations...\n",
      "Saved figures to ./derivatives/group-difference\n",
      "==================================================\n",
      "Saved figures to ./derivatives/group-difference\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Process each test type (1-sample and 2-sample)\n",
    "for brik_i, nii_fn, test, pthr in zip(brik_idx, nii_fns, tests, pthrs):\n",
    "    print(f\"\\n=== Processing {test_dict[test]} ===\")\n",
    "    \n",
    "    # Check if the output file already exists\n",
    "    if not os.path.exists(nii_fn):\n",
    "        print(f\"Creating {nii_fn}...\")\n",
    "        if test == \"1s\":\n",
    "            convert = f\"3dAFNItoNIFTI \\\n",
    "                -prefix {nii_fn} \\\n",
    "                {brik_fn}[{brik_i}]\"\n",
    "            os.system(convert)\n",
    "        elif test == \"2s\":\n",
    "            convert = f\"3dcalc -a {brik_fn}'[{brik_i}]' -expr '-1*a' -prefix {nii_fn}\"\n",
    "            os.system(convert)\n",
    "    else:\n",
    "        print(f\"File {nii_fn} already exists, skipping conversion.\")\n",
    "    \n",
    "    # Load and threshold images\n",
    "    nii_img = nib.load(nii_fn)\n",
    "    z_thresh = p_to_z(pthr)\n",
    "    clust_ext = cluster_df.loc[cluster_df[\"pthr\"] == pthr, alpha].values[0]\n",
    "    nii_thr_img = threshold_img(nii_img, z_thresh, cluster_threshold=clust_ext)\n",
    "    print(f\"Cluster extent: {clust_ext}, p-threshold: {pthr}, z-threshold: {z_thresh}\")\n",
    "    \n",
    "    # Calculate effect sizes (Cohen's d)\n",
    "    nii_arr = masker.transform(nii_img)\n",
    "    if test == \"1s\":\n",
    "        nii_cohen_arr = nii_arr / np.sqrt(n_sub)\n",
    "    elif test == \"2s\":\n",
    "        nii_cohen_arr = nii_arr / (np.sqrt(n_sub_1) + np.sqrt(n_sub_2))\n",
    "    \n",
    "    nii_cohen_img = masker.inverse_transform(nii_cohen_arr)\n",
    "    \n",
    "    # Create contour masks for visualization\n",
    "    nii_thr_arr = masker.transform(nii_thr_img)\n",
    "    nii_contour_arr = np.zeros_like(nii_thr_arr)\n",
    "    nii_contour_arr[(nii_thr_arr > z_thresh) | (nii_thr_arr < -z_thresh)] = 1\n",
    "    nii_contour_img = masker.inverse_transform(nii_contour_arr)\n",
    "    nii_contour_img_3d = index_img(nii_contour_img, 0)\n",
    "    \n",
    "    # Set visualization parameters\n",
    "    vmax = round(np.max(np.abs(nii_thr_arr)), 2)\n",
    "    vmax = 13 if vmax > 13 else vmax\n",
    "    c_vmax = 0.1 if test == \"2s\" else 0.3\n",
    "    \n",
    "    # Generate cluster table and save thresholded images\n",
    "    clusters = nilearn.reporting.get_clusters_table(\n",
    "        nii_thr_img, z_thresh, two_sided=True\n",
    "    )\n",
    "    print(\"Significant clusters:\")\n",
    "    print(clusters)\n",
    "    \n",
    "    # Save thresholded images to appropriate directories\n",
    "    if test == \"1s\":\n",
    "        thresh_fn = op.join(group_avg_dir, f\"sub-group_task-rest_desc-1SampletTest_thresh.nii.gz\")\n",
    "    elif test == \"2s\":\n",
    "        thresh_fn = op.join(group_diff_dir, f\"sub-group_task-rest_desc-2SampletTest_thresh.nii.gz\")\n",
    "    \n",
    "    nib.save(nii_thr_img, thresh_fn)\n",
    "    print(f\"Saved thresholded nifti: {thresh_fn}\")\n",
    "    \n",
    "    # Generate all visualizations\n",
    "    print(\"Generating visualizations...\")\n",
    "    \n",
    "    # First, get coordinates from the thresholded statistical map\n",
    "    from nilearn.plotting import find_xyz_cut_coords\n",
    "    coords = find_xyz_cut_coords(nii_thr_img, activation_threshold=z_thresh)\n",
    "    \n",
    "    stat_fig = plot_vol(nii_thr_img, z_thresh, vmax=vmax, cmap=CMAP, cut_coords=coords)\n",
    "    vol_fig = plot_vol(nii_thr_img, z_thresh, vmax=vmax, cmap=CMAP, cut_coords=coords)\n",
    "    cohen_fig = plot_vol(\n",
    "        nii_cohen_img,\n",
    "        cohen_thresh,\n",
    "        mask_contours=nii_contour_img_3d,\n",
    "        vmax=c_vmax,\n",
    "        alpha=0.8,\n",
    "        cmap=CMAP,\n",
    "        cut_coords=coords,\n",
    "    )\n",
    "    surf_fig = plot_surf(nii_thr_img, mask_contours=nii_contour_img_3d, vmax=vmax, cmap=CMAP)\n",
    "    \n",
    "    # Prepare data for decoding\n",
    "    if test == \"1s\":\n",
    "        nii_pos_arr = np.where(nii_arr > 0, nii_arr, 0)\n",
    "        img_to_decode = masker.inverse_transform(nii_pos_arr)\n",
    "    elif test == \"2s\":\n",
    "        nii_neg_arr = abs(np.where(nii_arr > 0, nii_arr, 0))\n",
    "        img_to_decode = masker.inverse_transform(nii_neg_arr)\n",
    "    \n",
    "    # Decode the image\n",
    "    corrs_df = decoder.transform(img_to_decode)\n",
    "    num_val = [int(lab.split(\"__\")[1].split(\"_\")[0]) for lab in corrs_df.index.to_list()]\n",
    "    indices = np.argsort(num_val)\n",
    "    corrs_df = corrs_df.iloc[indices]\n",
    "    filtered_df, filtered_features, filtered_frequencies = _decoding_filter(\n",
    "        corrs_df,\n",
    "        features,\n",
    "        classification,\n",
    "        freq_by_topic=frequencies,\n",
    "        class_by_topic=class_lst,\n",
    "    )\n",
    "    \n",
    "    # Visualize decoding results\n",
    "    corrs = filtered_df[\"r\"].to_numpy()\n",
    "    \n",
    "    # Save figures to appropriate directories\n",
    "    if test == \"1s\":\n",
    "        fig_save_dir = group_avg_dir\n",
    "    elif test == \"2s\":\n",
    "        fig_save_dir = group_diff_dir\n",
    "    \n",
    "    # Radar plot\n",
    "    plot_radar(\n",
    "        corrs,\n",
    "        filtered_features,\n",
    "        MODEL,\n",
    "        cmap=CMAP,\n",
    "        out_fig=op.join(fig_save_dir, f\"{test}_radar.png\"),\n",
    "    )\n",
    "    \n",
    "    # Word cloud plot\n",
    "    plot_cloud(\n",
    "        corrs,\n",
    "        filtered_features,\n",
    "        MODEL,\n",
    "        width=10,\n",
    "        height=5,\n",
    "        frequencies=filtered_frequencies,\n",
    "        cmap=CMAP,\n",
    "        out_fig=op.join(fig_save_dir, f\"{test}_wordcloud.png\"),\n",
    "    )\n",
    "    \n",
    "    vol_fig.savefig(op.join(fig_save_dir, f\"{test}_volume.png\"), bbox_inches=\"tight\", dpi=300)\n",
    "    cohen_fig.savefig(op.join(fig_save_dir, f\"{test}_volume-cohen.png\"), bbox_inches=\"tight\", dpi=300)\n",
    "    surf_fig.savefig(op.join(fig_save_dir, f\"{test}_surface.png\"), bbox_inches=\"tight\", dpi=300)\n",
    "    \n",
    "    print(f\"Saved figures to {fig_save_dir}\")\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine sub-figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Image file not found: ./derivatives/group-averaged/1s_surface-cohen.png\n",
      "Warning: Radar plot not found: ./derivatives/group-averaged/1s_radar.png\n",
      "Warning: Word cloud not found: ./derivatives/group-averaged/1s_wordcloud.png\n",
      "Saved combined figure: ./derivatives/combined_1s.png\n",
      "Warning: Image file not found: ./derivatives/group-difference/2s_surface-cohen.png\n",
      "Warning: Radar plot not found: ./derivatives/group-difference/2s_radar.png\n",
      "Warning: Word cloud not found: ./derivatives/group-difference/2s_wordcloud.png\n",
      "Saved combined figure: ./derivatives/combined_1s.png\n",
      "Warning: Image file not found: ./derivatives/group-difference/2s_surface-cohen.png\n",
      "Warning: Radar plot not found: ./derivatives/group-difference/2s_radar.png\n",
      "Warning: Word cloud not found: ./derivatives/group-difference/2s_wordcloud.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b0/6xxmhnys7hj9g_47_dsjm7c00000gn/T/ipykernel_80491/1518929970.py:62: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved combined figure: ./derivatives/combined_2s.png\n"
     ]
    }
   ],
   "source": [
    "for test in tests:\n",
    "    output_file = op.join(out_dir, f\"combined_{test}.png\")\n",
    "\n",
    "    figure1 = plt.figure(figsize=(10, 6))\n",
    "    gs = GridSpec(\n",
    "        nrows=2, ncols=4, figure=figure1\n",
    "    )  # Increase columns to 4 for better spacing\n",
    "\n",
    "    # Determine the correct directory for this test\n",
    "    if test == \"1s\":\n",
    "        fig_source_dir = group_avg_dir\n",
    "    elif test == \"2s\":\n",
    "        fig_source_dir = group_diff_dir\n",
    "\n",
    "    for col, data_type in enumerate([\"\", \"-cohen\"]):\n",
    "        img_files = [\n",
    "            op.join(fig_source_dir, f\"{test}_volume{data_type}.png\"),\n",
    "            op.join(fig_source_dir, f\"{test}_surface{data_type}.png\"),\n",
    "        ]\n",
    "\n",
    "        for row, fn in enumerate(img_files):\n",
    "            if os.path.exists(fn):\n",
    "                img1 = mpimg.imread(fn)\n",
    "                # if row == 0:\n",
    "                #    img1 = trim_image(img=img1, tol=1, fix=True)\n",
    "\n",
    "                ax = figure1.add_subplot(gs[row, col], aspect=\"equal\")\n",
    "                ax.imshow(img1)\n",
    "\n",
    "                if col == 0 and row == 0:\n",
    "                    ax.set_title(\"Z-Map\", fontsize=12)\n",
    "                if col == 1 and row == 0:\n",
    "                    ax.set_title(\"Effect Size\", fontsize=12)\n",
    "                ax.set_axis_off()\n",
    "            else:\n",
    "                print(f\"Warning: Image file not found: {fn}\")\n",
    "\n",
    "    # Radar plot in column 3, row 1 (if it exists)\n",
    "    radar_fn = op.join(fig_source_dir, f\"{test}_radar.png\")\n",
    "    if os.path.exists(radar_fn):\n",
    "        radar_img = mpimg.imread(radar_fn)\n",
    "        ax = figure1.add_subplot(gs[0, 2], aspect=\"equal\")\n",
    "        ax.imshow(radar_img)\n",
    "        ax.set_axis_off()\n",
    "    else:\n",
    "        print(f\"Warning: Radar plot not found: {radar_fn}\")\n",
    "\n",
    "    # Word cloud in column 3, row 2 (if it exists)\n",
    "    dec_fn = op.join(fig_source_dir, f\"{test}_wordcloud.png\")\n",
    "    if os.path.exists(dec_fn):\n",
    "        img1 = mpimg.imread(dec_fn)\n",
    "        ax = figure1.add_subplot(gs[1, 2], aspect=\"equal\")\n",
    "        ax.imshow(img1)\n",
    "        ax.set_axis_off()\n",
    "    else:\n",
    "        print(f\"Warning: Word cloud not found: {dec_fn}\")\n",
    "\n",
    "    figure1.suptitle(test_dict[test], fontsize=14)\n",
    "    figure1.subplots_adjust(wspace=0.01, hspace=0.001)\n",
    "    figure1.savefig(output_file, bbox_inches=\"tight\", dpi=300)\n",
    "    print(f\"Saved combined figure: {output_file}\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
